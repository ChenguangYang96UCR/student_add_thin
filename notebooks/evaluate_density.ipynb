{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('/home/cyang314/ucr_work/add-thin')\n",
    "\n",
    "from add_thin.metrics import MMD, lengths_distribution_wasserstein_distance\n",
    "from add_thin.evaluate_utils import get_task, get_run_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set run id and paths\n",
    "RUN_ID = \"naflz4ti\"\n",
    "\n",
    "WANDB_DIR = \"/home/cyang314/ucr_work/add-thin/wandb\"\n",
    "PROJECT_ROOT = \"/home/cyang314/ucr_work/add-thin/\"  # should include data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223.54166666666666\n",
      "198.16666666666669\n",
      "70.28472222222223\n"
     ]
    }
   ],
   "source": [
    "def sample_model(task, tmax, n=4000):\n",
    "    \"\"\"\n",
    "    Unconditionally draw n event sequences from Add Thin.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        samples = task.model.sample(n, tmax=tmax.to(task.device)).to_time_list()\n",
    "\n",
    "    assert len(samples) == n, \"not enough samples\"\n",
    "    x_N = task.model.get_x_N()\n",
    "    assert x_N != None\n",
    "    # assert len(x_N) == n, \"not enough samples\"\n",
    "    return samples, x_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyang314/ucr_work/add-thin/add_thin/data.py:659: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loader = torch.load(path, map_location=device)\n",
      "/home/cyang314/.conda/envs/add-thin/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)  # type: ignore[arg-type]\n",
      "/home/cyang314/ucr_work/add-thin/add_thin/distributions/intensities.py:268: UserWarning: Rejection sampling multiple increased to 3, as not enough event times were inside [0, tmax].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get run data\n",
    "data_name, seed, run_path = get_run_data(RUN_ID, WANDB_DIR)\n",
    "\n",
    "# Get task and datamodule\n",
    "task, datamodule = get_task(run_path, density=True, data_root=PROJECT_ROOT)\n",
    "\n",
    "# Get test sequences\n",
    "test_sequences = []\n",
    "for (\n",
    "    batch\n",
    ") in (\n",
    "    datamodule.test_dataloader()\n",
    "):  # batch is set to full test set, but better be safe\n",
    "    test_sequences = test_sequences + batch.to_time_list()\n",
    "\n",
    "# Sample event sequences from trained model\n",
    "samples, x_N = sample_model(task, datamodule.tmax, n=4000)\n",
    "stored_x_0_list = []\n",
    "stored_x_N_list = []\n",
    "stored_pair = []\n",
    "for k in range(1000):\n",
    "    store_samples, store_x_N = sample_model(task, datamodule.tmax, n=4000)\n",
    "    stored_pair.append([store_samples, store_x_N])\n",
    "\n",
    "np.save('./stored_pair.npy', stored_pair)\n",
    "\n",
    "# Evaluate metrics against test dataset\n",
    "mmd = MMD(\n",
    "    samples,\n",
    "    test_sequences,\n",
    "    datamodule.tmax.detach().cpu().item(),\n",
    ")[0]\n",
    "wasserstein = lengths_distribution_wasserstein_distance(\n",
    "    samples,\n",
    "    test_sequences,\n",
    "    datamodule.tmax.detach().cpu().item(),\n",
    "    datamodule.n_max,\n",
    ")\n",
    "\n",
    "# Print rounded results for data and seed\n",
    "print(\"ADD and Thin density evaluation:\")\n",
    "print(\"================================\")\n",
    "print(\n",
    "    f\"{data_name} (Seed: {seed}): MMD: {mmd:.3f}, Wasserstein: {wasserstein:.3f}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "add-thin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
