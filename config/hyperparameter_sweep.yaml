#./train.py --multirun hydra/launcher=slurm 

defaults:
  - data: data_set
  - task: density # density, forecast
  - hydra: default
  
  # Allow the model to overwrite the settings below
  - _self_
  - model: add_thin

optimization:
  optimizer_type: Adam

trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: gpu
  max_epochs: 5000
  log_every_n_steps: 1
  resume_from_checkpoint: ~
  check_val_every_n_epoch: 100
  gradient_clip_val: 2.
  gradient_clip_algorithm: value

seed: 135398
eval_testset: no

id: ~
entity: ~
project: add_thin_hyperparameter_sweep
group: ~
mode: ~
name: ~
run_dir: ~

early_stopping: 20

hydra:
  job:
      name: ${project}
  sweeper:
    params:
      seed: int(9591415),int(135398),int(428227),int(206247),int(687906)
      task.learning_rate: float(0.001),float(0.01)
      model.mix_components: int(16),int(8)
